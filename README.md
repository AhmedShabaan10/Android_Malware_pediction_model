# Android Malware Detection

## Team Members
- Ahmed Mohamed Shabaan (Sec 1)
- Ahmed Mohamed Ahmed Esmail (Sec 1)
- Eslam Hamdi Ragab Abdallah (Sec 2)

## About The Project

This project focuses on Android malware detection using machine learning techniques. The dataset comprises information about Android applications, categorized into four labels: Android_Adware, Android_Scareware, Android_SMS_Malware, and Benign. The data has been scraped from the CIC repository.

### Dataset Overview
- Total Entries: 355,630
- Columns: 85

[Link to Dataset on Kaggle](https://www.kaggle.com/datasets/subhajournal/android-malware-detection)

## Notebook Overview

The Jupyter notebook in this repository covers the entire machine learning workflow, including data preprocessing, encoding, splitting into training, validation, and test sets, feature scaling, model selection, evaluation, and visualization.

### Contents

1. **Data Cleaning**: Null value handling, encoding, and column removal.
2. **Data Splitting**: Division into training, validation, and test sets.
3. **Feature Scaling**: MinMax scaling for normalization.
4. **Model Selection and Evaluation**: Gaussian Naive Bayes, Multinomial Naive Bayes, Complement Naive Bayes, Bernoulli Naive Bayes, K-Nearest Neighbors, and Decision Tree Classifier.
5. **Results Visualization**: Bar plots comparing training, validation, and test accuracies.
6. **Confusion Matrix**: Visualizing the confusion matrix for the Decision Tree Classifier on the validation set.
7. **Decision Tree Visualization**: Visualizing the Decision Tree model.

## Usage

1. Ensure you have the required libraries installed.
2. Download the dataset from the provided Kaggle link.
3. Run the notebook cells sequentially for data processing, model training, and evaluation.

Feel free to experiment with other machine learning models or hyperparameter tuning for further improvement.

**Note:** Update the dataset path in the notebook according to your local directory structure.

## Libraries Used
- NumPy
- Matplotlib
- Pandas
- Scikit-learn
- Seaborn

## Model Performance

### Model Evaluation

Several machine learning models were evaluated, and here are the accuracy values on the training, validation, and test sets:

- **GaussianNB**
  - Training Accuracy: 0.6488
  - Validation Accuracy: 0.6474
  - Test Accuracy: 0.6469

- **MultinomialNB**
  - Training Accuracy: 0.7097
  - Validation Accuracy: 0.7095
  - Test Accuracy: 0.7080

- **ComplementNB**
  - Training Accuracy: 0.7607
  - Validation Accuracy: 0.7591
  - Test Accuracy: 0.7574

- **BernoulliNB**
  - Training Accuracy: 0.5904
  - Validation Accuracy: 0.5901
  - Test Accuracy: 0.5874

- **KNeighborsClassifier**
  - Training Accuracy: 0.9788
  - Validation Accuracy: 0.9661
  - Test Accuracy: 0.9660

- **DecisionTreeClassifier**
  - Training Accuracy: 1.0
  - Validation Accuracy: 1.0
  - Test Accuracy: 1.0

### Results Visualization

Results are visualized using bar plots to compare training, validation, and test accuracies for each model.

### Confusion Matrix

A confusion matrix was generated and visualized for the Decision Tree Classifier on the validation set.

### Decision Tree Visualization

The Decision Tree model was visualized to understand its decision-making process.

Feel free to explore and contribute to further enhance the project!

